{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity DRL Nanodegree Project Navigation\n",
    "\n",
    "This repository shows my approach to solve the Task in the Project Navigation.\n",
    "On https://github.com/udacity/Value-based-methods/tree/main/p1_navigation you can find the instructions for the Project provided by Udacity.\n",
    "\n",
    "As the topic of DRL is quite complex I will mostly rely on the Udacity provided Example Code to realize the DQN Agent. I will look at some hyperparameters and will try to optimize the Model Architecture for the local and the target QNetwork Model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Initialization of Environment\n",
    "### Import of libraries and own DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from dqn_agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Unity Banana Environment and Initialization of DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana_Linux/Banana.x86_64\")\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# extract the number of possible actions and the number of states in our environment\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size = brain.vector_observation_space_size\n",
    "\n",
    "# initialize the agent with these values\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train the Agent by running Banana Collection Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will test four different settings to validate two different assumptions:\n",
    "\n",
    "  - increase of Epsilon_decay `eps_decay` should improve the generalization and stability of the agent as it will do more exploration in favor over exploitation\n",
    "  - more dense models should also improve the ability to generalize of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 25\tAverage Score: 1.08\n",
      "Episode 50\tAverage Score: 5.96\n",
      "Episode 75\tAverage Score: 11.56\n",
      "Episode 100\tAverage Score: 21.68\n",
      "Episode 125\tAverage Score: 45.16\n",
      "Episode 150\tAverage Score: 85.34\n",
      "Episode 175\tAverage Score: 156.30\n",
      "Episode 200\tAverage Score: 256.90\n",
      "Episode 225\tAverage Score: 386.68\n",
      "Episode 250\tAverage Score: 544.63\n",
      "Episode 275\tAverage Score: 726.20\n",
      "Episode 300\tAverage Score: 940.76\n",
      "Episode 325\tAverage Score: 1189.69\n",
      "Episode 350\tAverage Score: 1468.45\n",
      "Episode 375\tAverage Score: 1760.30\n",
      "\n",
      "Environment solved in 370 episodes!\tAverage Score: 2002.67\n"
     ]
    }
   ],
   "source": [
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.990):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    score = 0\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        state = state[\"BananaBrain\"].vector_observations\n",
    "        for t in range(max_t):\n",
    "            # get the next action\n",
    "            action = agent.act(state, eps)\n",
    "            # do the next action in the environment\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            # get the resulting states from the environment\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            # collect the reward from the last action\n",
    "            reward = env_info.rewards[0]\n",
    "            # check if our episode is done\n",
    "            done = env_info.local_done[0]\n",
    "            # feed our current observation back to the QNetwork\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score into the window of last 100 scores\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        if i_episode % 25 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=2000.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-25, np.mean(scores_window)))\n",
    "            agent.save_checkpoint(\"simple_dqn_three_layers_0990.pth\")\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.title(\"BananaBrain Result with \\n eps_decay=0.990\\n 3-Layer Linear QNetwork\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview over all four training processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Training with six layers and EpsDecay 0990 | Training with six hidden layers and EpsDecay 0999 |  \n",
    "|--------------------------------------|--------------------------------------|\n",
    "| ![](images/bananabrain_dqn_five_layers_0990.png) | ![](images/bananabrain_dqn_five_layers_0999.png) | \n",
    "\n",
    "| Training with two layers and EpsDecay 0990 | Training with two layers and EpsDecay 0999 |  \n",
    "|--------------------------------------|--------------------------------------|\n",
    "| ![](images/bananabrain_dqn_two_layers_0990.png) | ![](images/bananabrain_dqn_two_layers_0999.png) | \n",
    "\n",
    "The overall training improvement over the episodes looks good for all four tried settings. The trainings with the higher density models took some more episodes to reach the performance of accumulative reward of 2000 over the last 100 episodes. Let's check their performance against the same environment again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Check trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the four resulting models, I will give each model another hundred episodes to show the performance of each.\n",
    "Moreover I want to check out, how big is the proportion of timesteps, where the Agent gets trapped inbetween two states, like in the GIF below.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"images/trapped.gif\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = brain.vector_action_space_size\n",
    "state_size = brain.vector_observation_space_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trapped_actions(action_list):\n",
    "    \"\"\"Count the length of agent movement where it get's trapped inbetween two states.\n",
    "    Outputs the number of consecutively actions without any development.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        action_list (list): list of actions from one episode\n",
    "    \"\"\"\n",
    "    repetition_count = 0\n",
    "    element_list = []\n",
    "    for el in reversed(action_list):\n",
    "        element_list.append(el)\n",
    "        if len(element_list) > 1:\n",
    "            if len(set(element_list)) == 2:\n",
    "                if element_list[-1] != element_list[-2]:\n",
    "                    repetition_count += 1\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "    return repetition_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model simple_dqn_three_layers_0990.pth\n",
      "Mean Trapped Actions: 120.4\n",
      "Mean Scores: 9.54\n",
      "\n",
      "Model simple_dqn_three_layers_0999.pth\n",
      "Mean Trapped Actions: 80.57\n",
      "Mean Scores: 11.01\n",
      "\n",
      "Model simple_dqn_six_layers_0990.pth\n",
      "Mean Trapped Actions: 135.82\n",
      "Mean Scores: 8.55\n",
      "\n",
      "Model simple_dqn_six_layers_0999.pth\n",
      "Mean Trapped Actions: 164.05\n",
      "Mean Scores: 6.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_list = [\n",
    "    (\"simple_dqn_three_layers_0990.pth\", \"flat\"),\n",
    "    (\"simple_dqn_three_layers_0999.pth\", \"flat\"),\n",
    "    (\"simple_dqn_six_layers_0990.pth\", \"deep\"),\n",
    "    (\"simple_dqn_six_layers_0999.pth\", \"deep\")\n",
    "]\n",
    "\n",
    "for model_checkpoint in model_list:\n",
    "    # initialize an new agent for every new model checkpoint\n",
    "    agent = Agent(state_size=state_size, action_size=action_size, seed=0, model=model_checkpoint[1])\n",
    "    agent.load_checkpoint(model_checkpoint[0])\n",
    "    mean_trapped_repetitions = []\n",
    "    mean_scores = []\n",
    "\n",
    "    for episode in range(100):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0]            # get the current state\n",
    "        score = 0                                          # initialize the score\n",
    "        action_list = []\n",
    "        while True:\n",
    "            action = agent.act(state, 0.0)                 # select an action\n",
    "            action_list.append(action)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            score += reward                                # update the score\n",
    "            state = next_state                             # roll over the state to next time step\n",
    "            if done:                                       # exit loop if episode finished\n",
    "                break\n",
    "        trapped_repetitions = count_trapped_actions(action_list)\n",
    "        mean_trapped_repetitions.append(trapped_repetitions)\n",
    "        mean_scores.append(score)\n",
    "    # calculate the mean over the reward scores and the number of trapped repeations\n",
    "    print(f\"Model {model_checkpoint[0]}\")\n",
    "    print(f\"Mean Trapped Actions: {mean(mean_trapped_repetitions)}\")\n",
    "    print(f\"Mean Scores: {mean(mean_scores)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "We can see, that a deeper (more dense) linear architecture is influencing the resulting Network in a very unfavorable way.\n",
    "We can also see, that increasing the Epsilon Decay factor, which leads to more Exploration over Exploitation, will decrease the performance of the deeper architecture even more.</div>\n",
    "\n",
    "> We can find in this article https://medium.com/analytics-vidhya/d2rl-deep-dense-architectures-in-reinforcement-learning-24419e6804b a confirmation of this observation. As in other Deep Learning domains we won't get better performance by simply increasing the densitiy of our model.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "The flat architecture improves it's performance by increasing the Epsilon Decay Factor which seems plausible too me, as increased intensity of Exploration should decrease the chance of getting trapped inbetween two states</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Ideas for Future Work\n",
    "\n",
    "I already discovered, that it isn't straight forward to change the model architecture for performance improvements.\n",
    "I also discovered, that some Hyperparameter like Epsilon Decay have a crucial impact on the resulting performance.\n",
    "\n",
    "Therefore some Ideas are:\n",
    "\n",
    "  * Following the recommendations in the mentionned blog post about deep dense architectures to adapt the model architecture in the context of DRL to improve the performance.\n",
    "  * Implement utilities to do hyperparameter optimization for DRL in a more automated approach. (can be hard to control the training environment).\n",
    "  \n",
    "Moreover in this course several concepts where mentionned, that have a proven research to increase the performance and stability of the resulting agent:\n",
    "\n",
    "  * Dueling DQN\n",
    "    * I'm pretty sure this adaption would decrease the occurence of trapped agents between two states\n",
    "  * Prioritized Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
